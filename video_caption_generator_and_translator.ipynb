{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachael9999/caption-generator/blob/main/video_caption_generator_and_translator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30dM9s2J27A5",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Select File From Google Drive (This is slow cuz it needs to read your whole drive in)**\n",
        "\n",
        "# @markdown <font size=\"3\">Navigate to the file you want to transcribe, left-click to highlight the file, then click 'Select' button to confirm.\n",
        "# @markdown <br/><font size=\"3\">If use local file, ignore this cell and move to the next.\n",
        "# @markdown <br/><font size=\"3\">If file uploaded to drive after execution, execute this cell again to refresh.\n",
        "!pip install geemap\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import os\n",
        "import logging\n",
        "from IPython.display import clear_output\n",
        "import geemap\n",
        "\n",
        "clear_output()\n",
        "drive.mount('/drive')\n",
        "\n",
        "print('Google Drive is mounted，please select file')\n",
        "\n",
        "from ipytree import Tree, Node\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interactive\n",
        "# import os\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "use_drive = True\n",
        "global drive_dir\n",
        "drive_dir = []\n",
        "\n",
        "def file_tree():\n",
        "    # create widgets as a simple file browser\n",
        "    full_widget = widgets.HBox()\n",
        "    left_widget = widgets.VBox()\n",
        "    right_widget = widgets.VBox()\n",
        "\n",
        "    path_widget = widgets.Text()\n",
        "    path_widget.layout.min_width = '300px'\n",
        "    select_widget = widgets.Button(\n",
        "      description='Select', button_style='primary', tooltip='Select current media file.'\n",
        "      )\n",
        "    drive_url = widgets.Output()\n",
        "\n",
        "    right_widget.children = [select_widget]\n",
        "    full_widget.children = [left_widget]\n",
        "\n",
        "    tree_widget = widgets.Output()\n",
        "    tree_widget.layout.max_width = '300px'\n",
        "    tree_widget.overflow = 'auto'\n",
        "\n",
        "    left_widget.children = [path_widget,tree_widget]\n",
        "\n",
        "    # init file tree\n",
        "    my_tree = Tree(multiple_selection=False)\n",
        "    my_tree_dict = {}\n",
        "    media_names = []\n",
        "\n",
        "    def select_file(b):\n",
        "        drive_dir.append(path_widget.value)\n",
        "        # full_widget.disabled = True\n",
        "        # clear_output()\n",
        "        print('File selected，please continue to select more or execute next cell')\n",
        "    #     if (out_file not in my_tree_dict.keys()) and (out_dir in my_tree_dict.keys()):\n",
        "    #         node = Node(os.path.basename(out_file))\n",
        "    #         my_tree_dict[out_file] = node\n",
        "    #         parent_node = my_tree_dict[out_dir]\n",
        "    #         parent_node.add_node(node)\n",
        "\n",
        "    select_widget.on_click(select_file)\n",
        "\n",
        "    def handle_file_click(event):\n",
        "        if event['new']:\n",
        "            cur_node = event['owner']\n",
        "            for key in my_tree_dict.keys():\n",
        "                if (cur_node is my_tree_dict[key]) and (os.path.isfile(key)):\n",
        "                    try:\n",
        "                        with open(key) as f:\n",
        "                            path_widget.value = key\n",
        "                            path_widget.disabled = False\n",
        "                            select_widget.disabled = False\n",
        "                            full_widget.children = [left_widget, right_widget]\n",
        "                    except Exception as e:\n",
        "                        path_widget.value = key\n",
        "                        path_widget.disabled = True\n",
        "                        select_widget.disabled = True\n",
        "\n",
        "                        return\n",
        "\n",
        "    def handle_folder_click(event):\n",
        "        if event['new']:\n",
        "            full_widget.children = [left_widget]\n",
        "\n",
        "    # redirect cwd to default drive root path and add nodes\n",
        "    my_dir = '/drive/MyDrive'\n",
        "    my_root_name = my_dir.split('/')[-1]\n",
        "    my_root_node = Node(my_root_name)\n",
        "    my_tree_dict[my_dir] = my_root_node\n",
        "    my_tree.add_node(my_root_node)\n",
        "    my_root_node.observe(handle_folder_click, 'selected')\n",
        "\n",
        "    for root, d_names, f_names in os.walk(my_dir):\n",
        "        folders = root.split('/')\n",
        "        for folder in folders:\n",
        "            if folder.startswith('.'):\n",
        "                continue\n",
        "        for d_name in d_names:\n",
        "            if d_name.startswith('.'):\n",
        "                d_names.remove(d_name)\n",
        "        for f_name in f_names:\n",
        "            # if f_name.startswith('.'):\n",
        "            #     f_names.remove(f_name)\n",
        "            # only add media files\n",
        "            if f_name.endswith(('mp3','m4a','flac','aac','wav','mp4','mkv','ts','flv')):\n",
        "                media_names.append(f_name)\n",
        "\n",
        "        d_names.sort()\n",
        "        f_names.sort()\n",
        "        media_names.sort()\n",
        "        keys = my_tree_dict.keys()\n",
        "\n",
        "        if root not in my_tree_dict.keys():\n",
        "          # print(f'root name is {root}') # folder path\n",
        "          name = root.split('/')[-1] # folder name\n",
        "          # print(f'folder name is {name}')\n",
        "          dir_name = os.path.dirname(root) # parent path of folder\n",
        "          # print(f'dir name is {dir_name}')\n",
        "          parent_node = my_tree_dict[dir_name]\n",
        "          node = Node(name)\n",
        "          my_tree_dict[root] = node\n",
        "          parent_node.add_node(node)\n",
        "          node.observe(handle_folder_click, 'selected')\n",
        "\n",
        "        if len(media_names) > 0:\n",
        "              parent_node = my_tree_dict[root] # parent folders\n",
        "              # print(parent_node)\n",
        "              parent_node.opened = False\n",
        "              for f_name in media_names:\n",
        "                  node = Node(f_name)\n",
        "                  node.icon = 'file'\n",
        "                  full_path = os.path.join(root, f_name)\n",
        "                  # print(full_path)\n",
        "                  my_tree_dict[full_path] = node\n",
        "                  parent_node.add_node(node)\n",
        "                  node.observe(handle_file_click, 'selected')\n",
        "        media_names.clear()\n",
        "\n",
        "    with tree_widget:\n",
        "      tree_widget.clear_output()\n",
        "      display(my_tree)\n",
        "\n",
        "    return full_widget\n",
        "\n",
        "\n",
        "tree= file_tree()\n",
        "tree\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "lKGNYjKXvo1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF_eOkuYbrBj",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Upload Local File**\n",
        "# @markdown <font size=\"3\"> **Upload the local file**\n",
        "\n",
        "from google.colab import files\n",
        "use_drive = False\n",
        "uploaded = files.upload()\n",
        "file_names = []\n",
        "file_names.append(list(uploaded.keys())[0])\n",
        "print('File uploaded，please continue to upload more or execute next cell')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown <font size=\"3\"> **If you upload the file from the left bar, run this cell**\n",
        "use_drive = False"
      ],
      "metadata": {
        "id": "cm0YRvitoHjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "use_drive = False\n",
        "\n",
        "#@markdown <br><center><img src='https://mega.nz/favicon.ico?v=3' height=\"50\" alt=\"MEGA-logo\"/></center>\n",
        "#@markdown <center><h2>Transfer from Mega to GDrive</h2></center><br>\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        ")\n",
        "#@title **transfer from mega link**\n",
        "URL = \"\" #@param {type:\"string\"}\n",
        "OUTPUT_PATH = \"\" #@param {type:\"string\"}\n",
        "if not OUTPUT_PATH:\n",
        "  os.makedirs(\"downloads\", exist_ok=True)\n",
        "  OUTPUT_PATH = \"downloads\"\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    loadingAn()\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "    clear_output()\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "\n",
        "def transfare():\n",
        "    import codecs\n",
        "    decoder = codecs.getincrementaldecoder(\"UTF-8\")()\n",
        "    cmd = [\"mega-get\", URL, OUTPUT_PATH]\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        print(line)\n",
        "\n",
        "\n",
        "transfare()\n",
        "\n"
      ],
      "metadata": {
        "id": "JUX3UVUaPmN9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **</br>【IMPORTANT】:** Make sure you select GPU as hardware accelerator in notebook settings, otherwise the processing speed will be very slow.\n",
        "\n",
        "Click on \"Runtime\" in the top menu, and then select \"Change runtime type\".\n",
        "In the popup window, select \"GPU\" as the hardware accelerator, and then click on \"Save\".\n",
        "Once you have selected the GPU, you can check if it is available by running the following code:"
      ],
      "metadata": {
        "id": "y8kquVjWvh6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "a_atuPElQXDk",
        "outputId": "90362c37-552e-4cfe-9e94-9ab15f443802"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install ffmpeg -y\n",
        "!pip install pydub\n",
        "!apt install ffmpeg\n",
        "!pip install faster-whisper\n",
        "!pip install pysubs2\n",
        "!pip install ffmpeg-python\n"
      ],
      "metadata": {
        "id": "p_XHll-IT4o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Combine VOB files (SKIP IF NOT)**\n",
        "import os\n",
        "import ffmpeg\n",
        "\n",
        "# Replace these with the actual filenames and directory\n",
        "File_Path = \"/content/downloads/Act I\" #@param {type:\"string\"}\n",
        "\n",
        "mp4_file = 'output.mp4'\n",
        "\n",
        "# Get a list of all files in the input directory with a .vob extension\n",
        "input_files = [\n",
        "    os.path.join(File_Path, filename)\n",
        "    for filename in os.listdir(File_Path)\n",
        "    if filename.lower().endswith('.vob')]\n",
        "\n",
        "input_files = sorted(input_files)\n",
        "\n",
        "input_string = \"|\".join([os.path.basename(file) for file in input_files])\n",
        "!ffmpeg -i \"concat:{input_string}\" -c copy output.vob\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nLcQRlS9EtYI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Extract the audio file from video.**\n",
        "# @markdown **Paste file path between \" \"**\n",
        "# @markdown <br/>**Skip this if you are uploading audio**\n",
        "# @markdown <br/> You can transcript video directly, but audio transcription and translation is faster\n",
        "#@title **transfer from mega link**\n",
        "File_Path = \"/content/output.vob\" #@param {type:\"string\"}\n",
        "file_basename = os.path.splitext(os.path.basename(File_Path))[0]\n",
        "!ffmpeg -i '{File_Path}' -f mp3 -ab 192000 -vn '{file_basename}.mp3'"
      ],
      "metadata": {
        "id": "xozk2KxZUFNl",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Separate audio into several subfiles (Whisper could transcribe audio of 2-3 hours now, so might not need this anymore).**\n",
        "# @markdown **Recommend for large file and translation**\n",
        "!pip install pydub\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "Audio_File_Name = \"output.mp3\" #@param {type:\"string\"}\n",
        "Segment_Time = 30 #@param {type:\"integer\"}\n",
        "\n",
        "audio_file = AudioSegment.from_file(Audio_File_Name)\n",
        "\n",
        "# Convert to mp3\n",
        "if audio_file.channels != 1:\n",
        "    audio_file = audio_file.set_channels(1) # convert to mono channel\n",
        "if audio_file.sample_width != 2:\n",
        "    audio_file = audio_file.set_sample_width(2) # set sample width to 16-bit\n",
        "mp3_audio = audio_file.export(format=\"mp3\")\n",
        "\n",
        "# Split audio file into segments\n",
        "segment_duration = Segment_Time * 60 * 1000 # in milliseconds\n",
        "segments = [audio_file[i:i+segment_duration] for i in range(0, len(audio_file), segment_duration)]\n",
        "\n",
        "if not os.path.exists(\"segments\"):\n",
        "    os.makedirs(\"segments\")\n",
        "\n",
        "for i, segment in enumerate(segments):\n",
        "    segment.export(f\"segments/segment_{i}.mp3\", format=\"mp3\")\n",
        "\n",
        "# Move the original audio file to the new directory\n",
        "if not os.path.exists(\"audio\"):\n",
        "    os.makedirs(\"audio\")\n",
        "os.rename(Audio_File_Name, f\"audio/{Audio_File_Name}\")\n"
      ],
      "metadata": {
        "id": "Qa3t8aXVUK0i",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Required settings:**\n",
        "\n",
        "\n",
        "# @markdown **【IMPORTANT】:**<font size=\"3\">Select uploaded file type.\n",
        "\n",
        "# encoding:utf-8\n",
        "file_type = \"audio\"  # @param [\"audio\",\"video\"]\n",
        "\n",
        "# @markdown <font size=\"3\">Model size will affect the processing time and transcribe quality.\n",
        "# @markdown <br/>**Base or small** model is enough for english/spanish transcription. Large-v1 is recommended for language with higher WER on fleurs\n",
        "# @markdown <br/>[Language Breakdown](https://github.com/openai/whisper/blob/main/language-breakdown.svg)\n",
        "# @markdown <br/>\n",
        "# @markdown <br/>The default source language is english. Please specify your own source language if applicable.\n",
        "# @markdown <br/>**Use two letter language code， e.g.  'en', 'ja'...**\n",
        "# @markdown <br/>[Language Code](https://gist.github.com/shad/209277)\n",
        "model_size = \"medium\"  # @param [\"base\",\"small\",\"medium\", \"large-v1\",\"large-v2\"]\n",
        "language = \"en\"  # @param {type:\"string\"}\n",
        "\n"
      ],
      "metadata": {
        "id": "YtTWrDwwBwQx",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Advanced settings**\n",
        "\n",
        "# @markdown <font size=\"3\">Option for split line text by spaces. The splited lines all use the same time stamp, with 'adjust_required' label as remark for manual adjustment.\n",
        "# @markdown <br/>\n",
        "# @markdown <br/> Modest: Start a new line if there are >5 words after the space\n",
        "# @markdown <br/> Aggressive: Start a new line as long as there is a space\n",
        "is_split = \"No\"  # @param [\"No\",\"Yes\"]\n",
        "split_method = \"Modest\"  # @param [\"Modest\",\"Aggressive\"]\n",
        "sub_style = \"default\"\n",
        "\n",
        "\n",
        "# @markdown **VAD filter**\n",
        "\n",
        "# @markdown <br/>[WARNING] VAD filter have pros and cons, please carefully select this option accroding to your own audio content.\n",
        "# @markdown <br/>[VAD filter](https://github.com/Ayanaminn/N46Whisper/blob/main/FAQ.md)\n",
        "\n",
        "\n",
        "is_vad_filter = \"False\" # @param [\"True\", \"False\"]\n",
        "# @markdown  <font size=\"2\"> *  The default <font size=\"3\">  ```min_silence_duration``` <font size=\"2\"> is set at 1000 ms in N46Whisper"
      ],
      "metadata": {
        "id": "dIYJsI0YBzE7",
        "cellView": "form"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Set the Directory**\n",
        "# @markdown <font size=\"3\"> All video files in the directory will be transcribed\n",
        "\n",
        "import os\n",
        "directory = \"/content/audio/\"  # @param {type:\"string\"}\n",
        "\n",
        "# Get a list of all files in the directory\n",
        "file_names = os.listdir(directory)\n",
        "\n",
        "# Filter the list to include only video or audio files\n",
        "video_audio_extensions = (\".mp4\", \".avi\", \".mov\", \".vob\", \".mp3\", \".wav\", \".flac\", \".m4a\")\n",
        "file_names = [file for file in file_names if os.path.splitext(file)[1].lower() in video_audio_extensions]\n",
        "\n",
        "print(file_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfOZf0ocQQJJ",
        "outputId": "ccff51df-f974-48c9-a9b7-065a9db1b03d",
        "cellView": "form"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jo Whiley Liam Gallagher co-hosts the show.m4a']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Run Whisper**\n",
        "#@markdown ass and srt file will be saved in the session storage (download before close!!).\n",
        "! pip install faster-whisper\n",
        "! pip install ffmpeg\n",
        "! wget https://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@raw.githubusercontent.com/Ayanaminn/N46Whisper/main/srt2ass.py\n",
        "! pip install pysubs2\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "import os\n",
        "import ffmpeg\n",
        "import subprocess\n",
        "import torch\n",
        "from faster_whisper import WhisperModel\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import pandas as pd\n",
        "import requests\n",
        "from urllib.parse import quote_plus\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import pysubs2\n",
        "import gc\n",
        "# assert file_name != \"\"\n",
        "# assert language != \"\"\n",
        "file_basenames = []\n",
        "\n",
        "if use_drive:\n",
        "    output_dir = os.path.dirname(drive_dir[0])\n",
        "    try:\n",
        "        file_names = drive_dir\n",
        "        for i in range(len(file_names)):\n",
        "          file_basenames.append(file_names[i].split('.')[0])\n",
        "        # print(file_name)\n",
        "        output_dir = os.path.dirname(drive_dir[0])\n",
        "    except Exception as e:\n",
        "            print(f'error: {e}')\n",
        "else:\n",
        "    all_files_exist = all(os.path.exists(os.path.join(directory, file_name)) for file_name in file_names)\n",
        "    if not all_files_exist:\n",
        "        raise ValueError(\"Not all files found in current path.\")\n",
        "    else:\n",
        "        try:\n",
        "            file_basenames = [os.path.splitext(file_name)[0] for file_name in file_names]\n",
        "            output_dir = directory\n",
        "        except Exception as e:\n",
        "            print(f'error: {e}')\n",
        "\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print('Loading model...')\n",
        "model = WhisperModel(model_size)\n",
        "\n",
        "os.chdir(directory)\n",
        "for i in range(len(file_names)):\n",
        "  file_name = file_names[i]\n",
        "  #Transcribe\n",
        "  file_basename = file_basenames[i]\n",
        "  if file_type == \"video\":\n",
        "    print('Extracting audio from video file...')\n",
        "    os.system(f'ffmpeg -i {file_name} -f mp3 -ab 192000 -vn {file_basename}.mp3')\n",
        "    print('Done.')\n",
        "  # print(file_basename)\n",
        "  tic = time.time()\n",
        "  print('Transcribe in progress...')\n",
        "  segments, info = model.transcribe(audio = f'{file_name}',\n",
        "                                      beam_size=5,\n",
        "                                      language=language,\n",
        "                                      vad_filter=is_vad_filter,\n",
        "                                      vad_parameters=dict(min_silence_duration_ms=1000))\n",
        "\n",
        "  # segments is a generator so the transcription only starts when you iterate over it\n",
        "  # to use pysubs2, the argument must be a segment list-of-dicts\n",
        "  total_duration = round(info.duration, 2)  # Same precision as the Whisper timestamps.\n",
        "  results= []\n",
        "  with tqdm(total=total_duration, unit=\" seconds\") as pbar:\n",
        "      for s in segments:\n",
        "          segment_dict = {'start':s.start,'end':s.end,'text':s.text}\n",
        "          results.append(segment_dict)\n",
        "          segment_duration = s.end - s.start\n",
        "          pbar.update(segment_duration)\n",
        "\n",
        "\n",
        "  #Time comsumed\n",
        "  toc = time.time()\n",
        "  print('Done')\n",
        "  print(f'Time consumpution {toc-tic}s')\n",
        "\n",
        "  subs = pysubs2.load_from_whisper(results)\n",
        "  subs.save(file_basename+'.srt')\n",
        "\n",
        "  from srt2ass import srt2ass\n",
        "  ass_sub = srt2ass(file_basename + \".srt\", sub_style, is_split,split_method)\n",
        "  print('ASS subtitle saved as: ' + ass_sub)\n",
        "\n",
        "  print(i+1, 'file(s) was completed!')\n",
        "  torch.cuda.empty_cache()\n",
        "print('All done!')"
      ],
      "metadata": {
        "id": "REXte-XnB3yM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Combine Separate srt back to one (Combine BEFORE gpt translation)**\n",
        "#@markdown Put the srt file path below, in order.\n",
        "File_Path = \"'/content/segments/segment_0.srt'\" #@param {type:\"string\"}\n",
        "\n",
        "file_list = []\n",
        "file_list.append(File_Path)\n",
        "print(file_list)"
      ],
      "metadata": {
        "id": "AI5Xz0ujeuTT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Combining (Combine BEFORE gpt translation)**\n",
        "# file_list = [\n",
        "#     '/content/segments/segment_0.srt',\n",
        "#     '/content/segments/segment_1.srt',\n",
        "#     '/content/segments/segment_2.srt'\n",
        "# ]\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "def adjust_srt_time(srt_file, seconds, count):\n",
        "    with open(srt_file, 'r') as file:\n",
        "        srt_data = file.read()\n",
        "\n",
        "    srt_lines = srt_data.split('\\n')\n",
        "\n",
        "    for i in range(len(srt_lines)):\n",
        "        if srt_lines[i].count('-->') == 1:\n",
        "            start_time, end_time = srt_lines[i].split('-->')\n",
        "            start_time = start_time.strip()\n",
        "            end_time = end_time.strip()\n",
        "\n",
        "            start_time = datetime.strptime(start_time, '%H:%M:%S,%f')\n",
        "            end_time = datetime.strptime(end_time, '%H:%M:%S,%f')\n",
        "\n",
        "            # Add the specified seconds to the start and end times\n",
        "            start_time += timedelta(seconds=seconds)\n",
        "            end_time += timedelta(seconds=seconds)\n",
        "\n",
        "            # Convert the start and end times back to strings\n",
        "            start_time = start_time.strftime('%H:%M:%S,%f')[:-3]\n",
        "            end_time = end_time.strftime('%H:%M:%S,%f')[:-3]\n",
        "\n",
        "            srt_lines[i] = f'{start_time} --> {end_time}'\n",
        "\n",
        "        # Check if the line is a subtitle text line\n",
        "        elif srt_lines[i].isdigit() and i < len(srt_lines)-1 and srt_lines[i+1] != '':\n",
        "            # Add the count of previous subtitle lines to the current count\n",
        "            srt_lines[i] = str(int(srt_lines[i]) + count)\n",
        "            count += 1\n",
        "\n",
        "    modified_srt_data = '\\n'.join(srt_lines)\n",
        "\n",
        "    return modified_srt_data, count\n",
        "\n",
        "count = 1\n",
        "\n",
        "combined_srt_data = ''\n",
        "\n",
        "for i in range(len(file_list)):\n",
        "\n",
        "    if i == 0:\n",
        "        with open(file_list[i], 'r') as file:\n",
        "            srt_data = file.read()\n",
        "\n",
        "        count += len(srt_data.split('\\n')) // 4  # Divide by 4 to count the number of subtitle text lines\n",
        "    else:\n",
        "        srt_data, count = adjust_srt_time(file_list[i], Segment_Time * 60 * i, count)  # Add 30 minutes (1800 seconds)\n",
        "\n",
        "    # Append the modified SRT data to the combined SRT data\n",
        "    combined_srt_data += srt_data + '\\n'\n",
        "\n",
        "with open('combined.srt', 'w') as file:\n",
        "    file.write(combined_srt_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "jzgdsKCkPEAO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5n2xrB631JV",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title **Translation using OpenAI:**\n",
        "\n",
        "# @markdown **AI Translation using GPT 3.5:**\n",
        "# @markdown **</br>**<font size=\"3\"> This feature allow users to translate previously transcribed subtitle text line by line using AI translation.\n",
        "# @markdown **</br>**It generates bilingual subtitle files in same sub style.</font>\n",
        "# @markdown **</br>[OpenAI key](https://openai.com/blog/openai-api) is billed monthly, check here to know**\n",
        "\n",
        "# @markdown **</br><font size=\"3\">Select subtitle file source</br>**\n",
        "sub_source = \"use_transcribed\"  # @param [\"use_transcribed\",\"upload_new\"]\n",
        "\n",
        "# @markdown **chatGPT:**\n",
        "# @markdown **</br>**<font size=\"2\"> Please input your own OpenAI API Key, then execute this cell.</font>\n",
        "# @markdown **</br>**<font size=\"2\">【Note】There are limitaions on usage for free API, consider paid plan to speed up.</font>\n",
        "openai_key = '' # @param {type:\"string\"}\n",
        "target_language = 'zh-hans'# @param [\"zh-hans\",\"english\"]\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import codecs\n",
        "import regex as re\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "\n",
        "clear_output()\n",
        "\n",
        "if sub_source == 'upload_new':\n",
        "  uploaded = files.upload()\n",
        "  sub_name = list(uploaded.keys())[0]\n",
        "  sub_basename = Path(sub_name).stem\n",
        "elif sub_source == 'use_transcribed':\n",
        "  sub_name = file_basenames[0] +'.ass'\n",
        "  sub_basename = file_basenames[0]\n",
        "\n",
        "!pip install openai\n",
        "!pip install pysubs2\n",
        "import openai\n",
        "import pysubs2\n",
        "\n",
        "clear_output()\n",
        "\n",
        "# original code\n",
        "class ChatGPTAPI():\n",
        "    def __init__(self, key, language):\n",
        "        self.key = key\n",
        "        # self.keys = itertools.cycle(key.split(\",\"))\n",
        "        self.language = language\n",
        "        self.key_len = len(key.split(\",\"))\n",
        "\n",
        "\n",
        "    # def rotate_key(self):\n",
        "    #     openai.api_key = next(self.keys)\n",
        "\n",
        "    def translate(self, text):\n",
        "        # print(text)\n",
        "        # self.rotate_key()\n",
        "        openai.api_key = self.key\n",
        "        try:\n",
        "            completion = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        # english prompt here to save tokens\n",
        "                        \"content\": f\"Please help me to translate,`{text}` to {self.language}, please return only translated content not include the origin text\",\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "            t_text = (\n",
        "                completion[\"choices\"][0]\n",
        "                .get(\"message\")\n",
        "                .get(\"content\")\n",
        "                .encode(\"utf8\")\n",
        "                .decode()\n",
        "            )\n",
        "        except Exception as e:\n",
        "            # TIME LIMIT for open api , pay to reduce the waiting time\n",
        "            sleep_time = int(60 / self.key_len)\n",
        "            time.sleep(sleep_time)\n",
        "            print(e, f\"will sleep  {sleep_time} seconds\")\n",
        "            # self.rotate_key()\n",
        "            openai.api_key = self.key\n",
        "            completion = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": f\"Please help me to translate,`{text}` to {self.language}, please return only translated content not include the origin text\",\n",
        "                    }\n",
        "                ],\n",
        "            )\n",
        "            t_text = (\n",
        "                completion[\"choices\"][0]\n",
        "                .get(\"message\")\n",
        "                .get(\"content\")\n",
        "                .encode(\"utf8\")\n",
        "                .decode()\n",
        "            )\n",
        "        # print(t_text)\n",
        "        return t_text\n",
        "\n",
        "class SubtitleTranslator():\n",
        "\n",
        "    def __init__(self, sub_src, model, key, language):\n",
        "        self.sub_src = sub_src\n",
        "        self.translate_model = model(key, language)\n",
        "\n",
        "    def translate_by_line(self):\n",
        "        sub_trans = pysubs2.load(self.sub_src)\n",
        "        total_lines = len(sub_trans)\n",
        "        for line in tqdm(sub_trans,total = total_lines):\n",
        "            line_trans = self.translate_model.translate(line.text)\n",
        "            line.text += (r'\\N'+ line_trans)\n",
        "            print(line_trans)\n",
        "\n",
        "        return sub_trans\n",
        "\n",
        "\n",
        "clear_output()\n",
        "\n",
        "translate_model = ChatGPTAPI\n",
        "\n",
        "assert translate_model is not None, \"unsupported model\"\n",
        "OPENAI_API_KEY = openai_key\n",
        "\n",
        "if not OPENAI_API_KEY:\n",
        "    raise Exception(\n",
        "        \"OpenAI API key not provided, please google how to obtain it\"\n",
        "    )\n",
        "# else:\n",
        "#     OPENAI_API_KEY = openai_key\n",
        "\n",
        "t = SubtitleTranslator(\n",
        "    sub_src=sub_name,\n",
        "    model= translate_model,\n",
        "    key = OPENAI_API_KEY,\n",
        "    language=target_language)\n",
        "\n",
        "translation = t.translate_by_line()\n",
        "\n",
        "#Save\n",
        "\n",
        "translation.save(sub_basename + '_translation.ass')\n",
        "translation.save(sub_basename + '_translation.srt')\n",
        "\n",
        "\n",
        "print('All done!')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}